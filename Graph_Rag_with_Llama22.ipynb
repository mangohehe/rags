{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mangohehe/rags/blob/main/Rag_with_Llama2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RAG System Using Llama2 With Hugging Face"
      ],
      "metadata": {
        "id": "tnUOq3dZeDK1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tHP9Gfafdq57"
      },
      "outputs": [],
      "source": [
        "!pip install pypdf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers einops accelerate langchain bitsandbytes"
      ],
      "metadata": {
        "id": "YYeHrwmHfbgB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Embedding\n",
        "!pip install -U sentence-transformers"
      ],
      "metadata": {
        "id": "Tu1g-xwnfv9s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade llama-index"
      ],
      "metadata": {
        "id": "urL9wZkqf-Zu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import VectorStoreIndex,SimpleDirectoryReader,ServiceContext,PromptTemplate"
      ],
      "metadata": {
        "id": "rRXji0B2twcD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-index-llms-huggingface\n",
        "from llama_index.llms.huggingface import HuggingFaceLLM"
      ],
      "metadata": {
        "id": "Q688JI5XuC2j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.prompts.prompts import SimpleInputPrompt"
      ],
      "metadata": {
        "id": "HutpiHgpgLBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents=SimpleDirectoryReader(\"/content/data\").load_data()\n",
        "documents"
      ],
      "metadata": {
        "id": "KcU-nQ_XgxWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt=\"\"\"\n",
        "You are a Job Seeking Advisor Assistant. Your primary role is to provide accurate and detailed advice on the skills required for specific job positions, based on the job descriptions and context provided. You should also guide users on how they can improve or acquire these skills to enhance their employability.\n",
        "\"\"\"\n",
        "## Default format supportable by LLama2\n",
        "query_wrapper_prompt=SimpleInputPrompt(\"{query_str}\")"
      ],
      "metadata": {
        "id": "2g7M89fKg54H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "id": "S5-mOhoIhfo0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "llm = HuggingFaceLLM(\n",
        "    context_window=4096,\n",
        "    max_new_tokens=256,\n",
        "    generate_kwargs={\"temperature\": 0.0, \"do_sample\": False},\n",
        "    system_prompt=system_prompt,\n",
        "    query_wrapper_prompt=query_wrapper_prompt,\n",
        "    tokenizer_name=\"meta-llama/Llama-2-7b-chat-hf\",\n",
        "    model_name=\"meta-llama/Llama-2-7b-chat-hf\",\n",
        "    device_map=\"auto\",\n",
        "    # uncomment this if using CUDA to reduce memory usage\n",
        "    model_kwargs={\"torch_dtype\": torch.float16 , \"load_in_8bit\":True}\n",
        ")"
      ],
      "metadata": {
        "id": "jyVOhSuhhqdb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain-community"
      ],
      "metadata": {
        "id": "gx6IdM6vNQqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
        "from llama_index.core import ServiceContext\n",
        "from llama_index.legacy.embeddings.langchain import LangchainEmbedding\n",
        "\n",
        "embed_model=LangchainEmbedding(\n",
        "    HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\"))"
      ],
      "metadata": {
        "id": "pr1EN5sViQm9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "service_context=ServiceContext.from_defaults(\n",
        "    chunk_size=1024,\n",
        "    llm=llm,\n",
        "    embed_model=embed_model\n",
        ")"
      ],
      "metadata": {
        "id": "LduiJD2ajpy4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "service_context"
      ],
      "metadata": {
        "id": "vQ_jtoK3kCeT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index=VectorStoreIndex.from_documents(documents,service_context=service_context)"
      ],
      "metadata": {
        "id": "31jvrW2BkFEL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index"
      ],
      "metadata": {
        "id": "IM-gNZ0-kRnO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_engine=index.as_query_engine()"
      ],
      "metadata": {
        "id": "uSJzrMm6kTxf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response=query_engine.query(\"what is attention is all you need?\")"
      ],
      "metadata": {
        "id": "PdhKFWCTkZRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response)"
      ],
      "metadata": {
        "id": "XKsLsgWSkfGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response=query_engine.query(\"what Machine Learning Software Engineer skills are required?\")"
      ],
      "metadata": {
        "id": "XHLOq8j2kyfF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response)"
      ],
      "metadata": {
        "id": "GMtcTcRHOSxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response)"
      ],
      "metadata": {
        "id": "PmWD4LdFk7zI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TJLTVLkelCRA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
